{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2a2be7a",
   "metadata": {},
   "source": [
    "### Problem statement: predicting turbine energy yield (TEY) using ambient variables as features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5214c9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-28T08:36:18.851406Z",
     "start_time": "2022-06-28T08:34:35.119295Z"
    }
   },
   "outputs": [],
   "source": [
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe996cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-28T08:37:25.219293Z",
     "start_time": "2022-06-28T08:37:19.342549Z"
    }
   },
   "outputs": [],
   "source": [
    "#!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8282e824",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-28T10:04:47.194252Z",
     "start_time": "2022-06-28T10:04:39.805161Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "# Create your first MLP in Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2777d6c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-28T12:42:16.900220Z",
     "start_time": "2022-06-28T12:42:16.835254Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>TEY</th>\n",
       "      <th>CDP</th>\n",
       "      <th>CO</th>\n",
       "      <th>NOX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.8594</td>\n",
       "      <td>1007.9</td>\n",
       "      <td>96.799</td>\n",
       "      <td>3.5000</td>\n",
       "      <td>19.663</td>\n",
       "      <td>1059.2</td>\n",
       "      <td>550.00</td>\n",
       "      <td>114.70</td>\n",
       "      <td>10.605</td>\n",
       "      <td>3.1547</td>\n",
       "      <td>82.722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.7850</td>\n",
       "      <td>1008.4</td>\n",
       "      <td>97.118</td>\n",
       "      <td>3.4998</td>\n",
       "      <td>19.728</td>\n",
       "      <td>1059.3</td>\n",
       "      <td>550.00</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.598</td>\n",
       "      <td>3.2363</td>\n",
       "      <td>82.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.8977</td>\n",
       "      <td>1008.8</td>\n",
       "      <td>95.939</td>\n",
       "      <td>3.4824</td>\n",
       "      <td>19.779</td>\n",
       "      <td>1059.4</td>\n",
       "      <td>549.87</td>\n",
       "      <td>114.71</td>\n",
       "      <td>10.601</td>\n",
       "      <td>3.2012</td>\n",
       "      <td>82.468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0569</td>\n",
       "      <td>1009.2</td>\n",
       "      <td>95.249</td>\n",
       "      <td>3.4805</td>\n",
       "      <td>19.792</td>\n",
       "      <td>1059.6</td>\n",
       "      <td>549.99</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.606</td>\n",
       "      <td>3.1923</td>\n",
       "      <td>82.670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.3978</td>\n",
       "      <td>1009.7</td>\n",
       "      <td>95.150</td>\n",
       "      <td>3.4976</td>\n",
       "      <td>19.765</td>\n",
       "      <td>1059.7</td>\n",
       "      <td>549.98</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.612</td>\n",
       "      <td>3.2484</td>\n",
       "      <td>82.311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       AT      AP      AH    AFDP    GTEP     TIT     TAT     TEY     CDP  \\\n",
       "0  6.8594  1007.9  96.799  3.5000  19.663  1059.2  550.00  114.70  10.605   \n",
       "1  6.7850  1008.4  97.118  3.4998  19.728  1059.3  550.00  114.72  10.598   \n",
       "2  6.8977  1008.8  95.939  3.4824  19.779  1059.4  549.87  114.71  10.601   \n",
       "3  7.0569  1009.2  95.249  3.4805  19.792  1059.6  549.99  114.72  10.606   \n",
       "4  7.3978  1009.7  95.150  3.4976  19.765  1059.7  549.98  114.72  10.612   \n",
       "\n",
       "       CO     NOX  \n",
       "0  3.1547  82.722  \n",
       "1  3.2363  82.776  \n",
       "2  3.2012  82.468  \n",
       "3  3.1923  82.670  \n",
       "4  3.2484  82.311  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gas_turbine_data_Original=pd.read_csv(\"gas_turbines.csv\")\n",
    "gas_turbine_data_Original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d51a39ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-28T12:43:12.495244Z",
     "start_time": "2022-06-28T12:43:12.460614Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>TEY</th>\n",
       "      <th>CDP</th>\n",
       "      <th>CO</th>\n",
       "      <th>NOX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.8594</td>\n",
       "      <td>1007.9</td>\n",
       "      <td>96.799</td>\n",
       "      <td>3.5000</td>\n",
       "      <td>19.663</td>\n",
       "      <td>1059.2</td>\n",
       "      <td>550.00</td>\n",
       "      <td>114.70</td>\n",
       "      <td>10.605</td>\n",
       "      <td>3.1547</td>\n",
       "      <td>82.722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.7850</td>\n",
       "      <td>1008.4</td>\n",
       "      <td>97.118</td>\n",
       "      <td>3.4998</td>\n",
       "      <td>19.728</td>\n",
       "      <td>1059.3</td>\n",
       "      <td>550.00</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.598</td>\n",
       "      <td>3.2363</td>\n",
       "      <td>82.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.8977</td>\n",
       "      <td>1008.8</td>\n",
       "      <td>95.939</td>\n",
       "      <td>3.4824</td>\n",
       "      <td>19.779</td>\n",
       "      <td>1059.4</td>\n",
       "      <td>549.87</td>\n",
       "      <td>114.71</td>\n",
       "      <td>10.601</td>\n",
       "      <td>3.2012</td>\n",
       "      <td>82.468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0569</td>\n",
       "      <td>1009.2</td>\n",
       "      <td>95.249</td>\n",
       "      <td>3.4805</td>\n",
       "      <td>19.792</td>\n",
       "      <td>1059.6</td>\n",
       "      <td>549.99</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.606</td>\n",
       "      <td>3.1923</td>\n",
       "      <td>82.670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.3978</td>\n",
       "      <td>1009.7</td>\n",
       "      <td>95.150</td>\n",
       "      <td>3.4976</td>\n",
       "      <td>19.765</td>\n",
       "      <td>1059.7</td>\n",
       "      <td>549.98</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.612</td>\n",
       "      <td>3.2484</td>\n",
       "      <td>82.311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15034</th>\n",
       "      <td>9.0301</td>\n",
       "      <td>1005.6</td>\n",
       "      <td>98.460</td>\n",
       "      <td>3.5421</td>\n",
       "      <td>19.164</td>\n",
       "      <td>1049.7</td>\n",
       "      <td>546.21</td>\n",
       "      <td>111.61</td>\n",
       "      <td>10.400</td>\n",
       "      <td>4.5186</td>\n",
       "      <td>79.559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15035</th>\n",
       "      <td>7.8879</td>\n",
       "      <td>1005.9</td>\n",
       "      <td>99.093</td>\n",
       "      <td>3.5059</td>\n",
       "      <td>19.414</td>\n",
       "      <td>1046.3</td>\n",
       "      <td>543.22</td>\n",
       "      <td>111.78</td>\n",
       "      <td>10.433</td>\n",
       "      <td>4.8470</td>\n",
       "      <td>79.917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15036</th>\n",
       "      <td>7.2647</td>\n",
       "      <td>1006.3</td>\n",
       "      <td>99.496</td>\n",
       "      <td>3.4770</td>\n",
       "      <td>19.530</td>\n",
       "      <td>1037.7</td>\n",
       "      <td>537.32</td>\n",
       "      <td>110.19</td>\n",
       "      <td>10.483</td>\n",
       "      <td>7.9632</td>\n",
       "      <td>90.912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15037</th>\n",
       "      <td>7.0060</td>\n",
       "      <td>1006.8</td>\n",
       "      <td>99.008</td>\n",
       "      <td>3.4486</td>\n",
       "      <td>19.377</td>\n",
       "      <td>1043.2</td>\n",
       "      <td>541.24</td>\n",
       "      <td>110.74</td>\n",
       "      <td>10.533</td>\n",
       "      <td>6.2494</td>\n",
       "      <td>93.227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15038</th>\n",
       "      <td>6.9279</td>\n",
       "      <td>1007.2</td>\n",
       "      <td>97.533</td>\n",
       "      <td>3.4275</td>\n",
       "      <td>19.306</td>\n",
       "      <td>1049.9</td>\n",
       "      <td>545.85</td>\n",
       "      <td>111.58</td>\n",
       "      <td>10.583</td>\n",
       "      <td>4.9816</td>\n",
       "      <td>92.498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15039 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           AT      AP      AH    AFDP    GTEP     TIT     TAT     TEY     CDP  \\\n",
       "0      6.8594  1007.9  96.799  3.5000  19.663  1059.2  550.00  114.70  10.605   \n",
       "1      6.7850  1008.4  97.118  3.4998  19.728  1059.3  550.00  114.72  10.598   \n",
       "2      6.8977  1008.8  95.939  3.4824  19.779  1059.4  549.87  114.71  10.601   \n",
       "3      7.0569  1009.2  95.249  3.4805  19.792  1059.6  549.99  114.72  10.606   \n",
       "4      7.3978  1009.7  95.150  3.4976  19.765  1059.7  549.98  114.72  10.612   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "15034  9.0301  1005.6  98.460  3.5421  19.164  1049.7  546.21  111.61  10.400   \n",
       "15035  7.8879  1005.9  99.093  3.5059  19.414  1046.3  543.22  111.78  10.433   \n",
       "15036  7.2647  1006.3  99.496  3.4770  19.530  1037.7  537.32  110.19  10.483   \n",
       "15037  7.0060  1006.8  99.008  3.4486  19.377  1043.2  541.24  110.74  10.533   \n",
       "15038  6.9279  1007.2  97.533  3.4275  19.306  1049.9  545.85  111.58  10.583   \n",
       "\n",
       "           CO     NOX  \n",
       "0      3.1547  82.722  \n",
       "1      3.2363  82.776  \n",
       "2      3.2012  82.468  \n",
       "3      3.1923  82.670  \n",
       "4      3.2484  82.311  \n",
       "...       ...     ...  \n",
       "15034  4.5186  79.559  \n",
       "15035  4.8470  79.917  \n",
       "15036  7.9632  90.912  \n",
       "15037  6.2494  93.227  \n",
       "15038  4.9816  92.498  \n",
       "\n",
       "[15039 rows x 11 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gas_turbine_data_Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84195128",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-28T10:04:53.126807Z",
     "start_time": "2022-06-28T10:04:53.029159Z"
    }
   },
   "outputs": [],
   "source": [
    "gas_ambients=gas_turbine_data_Original[['AT','AP','AH','TEY']].copy()\n",
    "gas_ambients.to_csv(\"gas_ambients.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "00df9c49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-28T12:43:56.422612Z",
     "start_time": "2022-06-28T12:43:56.371650Z"
    }
   },
   "outputs": [],
   "source": [
    "gas_turbine = numpy.loadtxt(\"gas_turbines.csv\", delimiter=\",\", skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cbfc7a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-28T10:05:02.332608Z",
     "start_time": "2022-06-28T10:05:02.283306Z"
    }
   },
   "outputs": [],
   "source": [
    "gas_ambients_data=numpy.loadtxt(\"gas_ambients.csv\", delimiter=\",\", skiprows=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c787d5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-28T10:05:03.887695Z",
     "start_time": "2022-06-28T10:05:03.863453Z"
    }
   },
   "source": [
    "##### gas_ambients_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f781f28a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-28T10:05:07.354338Z",
     "start_time": "2022-06-28T10:05:07.338616Z"
    }
   },
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c2be42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-28T10:01:27.387603Z",
     "start_time": "2022-06-28T10:01:27.371778Z"
    }
   },
   "outputs": [],
   "source": [
    "gas_turbine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ded8ba22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-28T10:07:08.174203Z",
     "start_time": "2022-06-28T10:07:08.162350Z"
    }
   },
   "outputs": [],
   "source": [
    "# split into input (X) and output (Y) variables\n",
    "X_amb = gas_ambients_data[:,0:4]\n",
    "Y2_amb = gas_ambients_data[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9463edb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-28T10:07:15.455038Z",
     "start_time": "2022-06-28T10:07:15.434734Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0000e+00, 6.8594e+00, 1.0079e+03, 9.6799e+01],\n",
       "       [1.0000e+00, 6.7850e+00, 1.0084e+03, 9.7118e+01],\n",
       "       [2.0000e+00, 6.8977e+00, 1.0088e+03, 9.5939e+01],\n",
       "       ...,\n",
       "       [1.5036e+04, 7.2647e+00, 1.0063e+03, 9.9496e+01],\n",
       "       [1.5037e+04, 7.0060e+00, 1.0068e+03, 9.9008e+01],\n",
       "       [1.5038e+04, 6.9279e+00, 1.0072e+03, 9.7533e+01]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_amb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "822cc161",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-28T10:07:23.003840Z",
     "start_time": "2022-06-28T10:07:22.987807Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([114.7 , 114.72, 114.71, ..., 110.19, 110.74, 111.58])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y2_amb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470abfe3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-28T10:01:36.685788Z",
     "start_time": "2022-06-28T10:01:36.675255Z"
    }
   },
   "outputs": [],
   "source": [
    "# # split into input (X) and output (Y) variables\n",
    "# X1 = gas_turbine[:,0:8]\n",
    "# Y1 = gas_turbine[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a598478",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-28T10:01:48.932910Z",
     "start_time": "2022-06-28T10:01:48.917369Z"
    }
   },
   "outputs": [],
   "source": [
    "# X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1bb282",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-28T10:01:54.399610Z",
     "start_time": "2022-06-28T10:01:54.390368Z"
    }
   },
   "outputs": [],
   "source": [
    "# Y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "caeac573",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-28T11:39:37.213887Z",
     "start_time": "2022-06-28T11:39:37.161033Z"
    }
   },
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=4,activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c05ed18d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-28T11:39:44.428789Z",
     "start_time": "2022-06-28T11:39:44.402820Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "adb7ca0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-28T12:11:17.702926Z",
     "start_time": "2022-06-28T12:03:03.966040Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -470709501952.0000 - accuracy: 0.0000e+00 - val_loss: -1084698591232.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -539605893120.0000 - accuracy: 0.0000e+00 - val_loss: -1239454580736.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -614623215616.0000 - accuracy: 0.0000e+00 - val_loss: -1407506841600.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -695949787136.0000 - accuracy: 0.0000e+00 - val_loss: -1589559689216.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -783749349376.0000 - accuracy: 0.0000e+00 - val_loss: -1785468289024.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -878327693312.0000 - accuracy: 0.0000e+00 - val_loss: -1996389744640.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/250\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -980101955584.0000 - accuracy: 0.0000e+00 - val_loss: -2223530573824.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -1089218347008.0000 - accuracy: 0.0000e+00 - val_loss: -2465888993280.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -1205689516032.0000 - accuracy: 0.0000e+00 - val_loss: -2724575838208.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -1329908023296.0000 - accuracy: 0.0000e+00 - val_loss: -3000229167104.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -1462190997504.0000 - accuracy: 0.0000e+00 - val_loss: -3293849059328.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -1602743959552.0000 - accuracy: 0.0000e+00 - val_loss: -3605364998144.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -1751690510336.0000 - accuracy: 0.0000e+00 - val_loss: -3935006621696.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -1909372616704.0000 - accuracy: 0.0000e+00 - val_loss: -4283627470848.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/250\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -2075779530752.0000 - accuracy: 0.0000e+00 - val_loss: -4650964090880.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -2251165532160.0000 - accuracy: 0.0000e+00 - val_loss: -5038191149056.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -2435773628416.0000 - accuracy: 0.0000e+00 - val_loss: -5445759533056.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -2630416596992.0000 - accuracy: 0.0000e+00 - val_loss: -5874907086848.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -2834782224384.0000 - accuracy: 0.0000e+00 - val_loss: -6325180301312.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -3049118498816.0000 - accuracy: 0.0000e+00 - val_loss: -6796992315392.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -3273677602816.0000 - accuracy: 0.0000e+00 - val_loss: -7291344519168.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -3509136130048.0000 - accuracy: 0.0000e+00 - val_loss: -7809680801792.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -3755118166016.0000 - accuracy: 0.0000e+00 - val_loss: -8349932322816.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -4012189679616.0000 - accuracy: 0.0000e+00 - val_loss: -8915604471808.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -4280084594688.0000 - accuracy: 0.0000e+00 - val_loss: -9503421497344.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -4559752658944.0000 - accuracy: 0.0000e+00 - val_loss: -10118010765312.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -4851408306176.0000 - accuracy: 0.0000e+00 - val_loss: -10758974865408.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -5155146170368.0000 - accuracy: 0.0000e+00 - val_loss: -11424328843264.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -5470761254912.0000 - accuracy: 0.0000e+00 - val_loss: -12116580892672.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -5798484246528.0000 - accuracy: 0.0000e+00 - val_loss: -12834357379072.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -6138821607424.0000 - accuracy: 0.0000e+00 - val_loss: -13580763136000.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -6491843592192.0000 - accuracy: 0.0000e+00 - val_loss: -14353933795328.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -6858417897472.0000 - accuracy: 0.0000e+00 - val_loss: -15156824244224.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -7237903319040.0000 - accuracy: 0.0000e+00 - val_loss: -15987278610432.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -7630593982464.0000 - accuracy: 0.0000e+00 - val_loss: -16845736247296.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -8037111693312.0000 - accuracy: 0.0000e+00 - val_loss: -17736012922880.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -8457830793216.0000 - accuracy: 0.0000e+00 - val_loss: -18656153042944.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -8892688891904.0000 - accuracy: 0.0000e+00 - val_loss: -19607031119872.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -9341620977664.0000 - accuracy: 0.0000e+00 - val_loss: -20587512594432.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -9805736443904.0000 - accuracy: 0.0000e+00 - val_loss: -21602232172544.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -10284722814976.0000 - accuracy: 0.0000e+00 - val_loss: -22648543248384.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -10777731792896.0000 - accuracy: 0.0000e+00 - val_loss: -23725929922560.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -11286489333760.0000 - accuracy: 0.0000e+00 - val_loss: -24836264951808.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -11810480586752.0000 - accuracy: 0.0000e+00 - val_loss: -25980049555456.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -12350616764416.0000 - accuracy: 0.0000e+00 - val_loss: -27159749984256.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1008/1008 [==============================] - 2s 2ms/step - loss: -12907628724224.0000 - accuracy: 0.0000e+00 - val_loss: -28375362043904.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -13480635662336.0000 - accuracy: 0.0000e+00 - val_loss: -29625390465024.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -14069895528448.0000 - accuracy: 0.0000e+00 - val_loss: -30910405672960.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -14676077314048.0000 - accuracy: 0.0000e+00 - val_loss: -32233737945088.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -15298875883520.0000 - accuracy: 0.0000e+00 - val_loss: -33589638987776.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -15937578205184.0000 - accuracy: 0.0000e+00 - val_loss: -34979992043520.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -16593736171520.0000 - accuracy: 0.0000e+00 - val_loss: -36412866953216.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -17267982073856.0000 - accuracy: 0.0000e+00 - val_loss: -37882538491904.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -17960909406208.0000 - accuracy: 0.0000e+00 - val_loss: -39392760561664.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -18672133341184.0000 - accuracy: 0.0000e+00 - val_loss: -40941679280128.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -19401568944128.0000 - accuracy: 0.0000e+00 - val_loss: -42529756020736.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -20148863893504.0000 - accuracy: 0.0000e+00 - val_loss: -44158764974080.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -20914582323200.0000 - accuracy: 0.0000e+00 - val_loss: -45825304559616.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -21700076896256.0000 - accuracy: 0.0000e+00 - val_loss: -47534772846592.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -22504175304704.0000 - accuracy: 0.0000e+00 - val_loss: -49284040884224.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -23327148081152.0000 - accuracy: 0.0000e+00 - val_loss: -51076707385344.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -24169859252224.0000 - accuracy: 0.0000e+00 - val_loss: -52910608089088.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -25033369976832.0000 - accuracy: 0.0000e+00 - val_loss: -54790558056448.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -25916795256832.0000 - accuracy: 0.0000e+00 - val_loss: -56711742226432.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -26820231561216.0000 - accuracy: 0.0000e+00 - val_loss: -58678971465728.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -27745817985024.0000 - accuracy: 0.0000e+00 - val_loss: -60690303811584.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -28690769510400.0000 - accuracy: 0.0000e+00 - val_loss: -62744988483584.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -29657453821952.0000 - accuracy: 0.0000e+00 - val_loss: -64847316254720.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -30642496602112.0000 - accuracy: 0.0000e+00 - val_loss: -66985102671872.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -31649049870336.0000 - accuracy: 0.0000e+00 - val_loss: -69176198692864.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -32678399180800.0000 - accuracy: 0.0000e+00 - val_loss: -71413302034432.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -33729368031232.0000 - accuracy: 0.0000e+00 - val_loss: -73697536770048.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -34803114049536.0000 - accuracy: 0.0000e+00 - val_loss: -76031465619456.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -35899303788544.0000 - accuracy: 0.0000e+00 - val_loss: -78413855457280.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -37018046300160.0000 - accuracy: 0.0000e+00 - val_loss: -80844186189824.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -38159018622976.0000 - accuracy: 0.0000e+00 - val_loss: -83321853837312.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -39323567128576.0000 - accuracy: 0.0000e+00 - val_loss: -85852512321536.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -40512086081536.0000 - accuracy: 0.0000e+00 - val_loss: -88433687003136.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -41722323140608.0000 - accuracy: 0.0000e+00 - val_loss: -91062131490816.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -42956027330560.0000 - accuracy: 0.0000e+00 - val_loss: -93740362366976.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -44214666657792.0000 - accuracy: 0.0000e+00 - val_loss: -96476340420608.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -45497708445696.0000 - accuracy: 0.0000e+00 - val_loss: -99258539704320.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -46804603240448.0000 - accuracy: 0.0000e+00 - val_loss: -102098595217408.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -48135338459136.0000 - accuracy: 0.0000e+00 - val_loss: -104985366888448.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -49492539736064.0000 - accuracy: 0.0000e+00 - val_loss: -107934851792896.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -50874667761664.0000 - accuracy: 0.0000e+00 - val_loss: -110931640057856.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -52280648794112.0000 - accuracy: 0.0000e+00 - val_loss: -113984967540736.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -53713272045568.0000 - accuracy: 0.0000e+00 - val_loss: -117092258938880.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -55171526688768.0000 - accuracy: 0.0000e+00 - val_loss: -120259000401920.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -56655651799040.0000 - accuracy: 0.0000e+00 - val_loss: -123475620528128.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1008/1008 [==============================] - 2s 2ms/step - loss: -58165655764992.0000 - accuracy: 0.0000e+00 - val_loss: -126754559623168.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -59700796194816.0000 - accuracy: 0.0000e+00 - val_loss: -130081867431936.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -61262390099968.0000 - accuracy: 0.0000e+00 - val_loss: -133471183831040.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -62851813212160.0000 - accuracy: 0.0000e+00 - val_loss: -136918247407616.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -64468990033920.0000 - accuracy: 0.0000e+00 - val_loss: -140426136780800.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -66110699339776.0000 - accuracy: 0.0000e+00 - val_loss: -143984986947584.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -67779495460864.0000 - accuracy: 0.0000e+00 - val_loss: -147605409497088.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -69476242423808.0000 - accuracy: 0.0000e+00 - val_loss: -151288796938240.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -71204064985088.0000 - accuracy: 0.0000e+00 - val_loss: -155032330698752.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -72958533959680.0000 - accuracy: 0.0000e+00 - val_loss: -158836430209024.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -74742405005312.0000 - accuracy: 0.0000e+00 - val_loss: -162705826643968.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -76555418075136.0000 - accuracy: 0.0000e+00 - val_loss: -166636208259072.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -78395962556416.0000 - accuracy: 0.0000e+00 - val_loss: -170621468147712.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/250\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -80263115702272.0000 - accuracy: 0.0000e+00 - val_loss: -174669323829248.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/250\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -82162464325632.0000 - accuracy: 0.0000e+00 - val_loss: -178789086658560.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/250\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -84090149666816.0000 - accuracy: 0.0000e+00 - val_loss: -182964231077888.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/250\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -86047815892992.0000 - accuracy: 0.0000e+00 - val_loss: -187208799617024.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -88032510214144.0000 - accuracy: 0.0000e+00 - val_loss: -191510863675392.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -90048502431744.0000 - accuracy: 0.0000e+00 - val_loss: -195876144283648.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -92097151500288.0000 - accuracy: 0.0000e+00 - val_loss: -200320294584320.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -94175722733568.0000 - accuracy: 0.0000e+00 - val_loss: -204820547895296.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -96283419213824.0000 - accuracy: 0.0000e+00 - val_loss: -209387138318336.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -98423445389312.0000 - accuracy: 0.0000e+00 - val_loss: -214021357699072.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -100595843203072.0000 - accuracy: 0.0000e+00 - val_loss: -218733020708864.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -102799807348736.0000 - accuracy: 0.0000e+00 - val_loss: -223504108617728.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -105036570951680.0000 - accuracy: 0.0000e+00 - val_loss: -228352623378432.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -107305739747328.0000 - accuracy: 0.0000e+00 - val_loss: -233268347666432.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -109604486774784.0000 - accuracy: 0.0000e+00 - val_loss: -238244620926976.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -111934531698688.0000 - accuracy: 0.0000e+00 - val_loss: -243290519633920.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -114295866130432.0000 - accuracy: 0.0000e+00 - val_loss: -248405473361920.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -116694336929792.0000 - accuracy: 0.0000e+00 - val_loss: -253599951093760.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -119126362161152.0000 - accuracy: 0.0000e+00 - val_loss: -258867745259520.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -121586145296384.0000 - accuracy: 0.0000e+00 - val_loss: -264188219883520.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -124081949114368.0000 - accuracy: 0.0000e+00 - val_loss: -269601120190464.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -126614243377152.0000 - accuracy: 0.0000e+00 - val_loss: -275081364242432.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -129180368896000.0000 - accuracy: 0.0000e+00 - val_loss: -280639018369024.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 127/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -131779159654400.0000 - accuracy: 0.0000e+00 - val_loss: -286259704496128.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -134412620529664.0000 - accuracy: 0.0000e+00 - val_loss: -291963152629760.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 129/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -137080759910400.0000 - accuracy: 0.0000e+00 - val_loss: -297741662027776.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 130/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -139781799411712.0000 - accuracy: 0.0000e+00 - val_loss: -303582582669312.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -142516007469056.0000 - accuracy: 0.0000e+00 - val_loss: -309507490054144.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -145290304684032.0000 - accuracy: 0.0000e+00 - val_loss: -315512324096000.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -148096025624576.0000 - accuracy: 0.0000e+00 - val_loss: -321582186627072.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 134/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -150940686483456.0000 - accuracy: 0.0000e+00 - val_loss: -327744692944896.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 135/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1008/1008 [==============================] - 2s 2ms/step - loss: -153823968493568.0000 - accuracy: 0.0000e+00 - val_loss: -333981924982784.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 136/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -156738942664704.0000 - accuracy: 0.0000e+00 - val_loss: -340284353282048.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -159686649184256.0000 - accuracy: 0.0000e+00 - val_loss: -346664158101504.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 138/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -162673882824704.0000 - accuracy: 0.0000e+00 - val_loss: -353132009750528.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 139/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -165698160558080.0000 - accuracy: 0.0000e+00 - val_loss: -359673010061312.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -168766226825216.0000 - accuracy: 0.0000e+00 - val_loss: -366327055253504.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 141/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -171869542023168.0000 - accuracy: 0.0000e+00 - val_loss: -373033680240640.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 142/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -175007988711424.0000 - accuracy: 0.0000e+00 - val_loss: -379830231105536.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 143/250\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -178188797870080.0000 - accuracy: 0.0000e+00 - val_loss: -386709359427584.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 144/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -181404939845632.0000 - accuracy: 0.0000e+00 - val_loss: -393663146360832.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 145/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -184655827435520.0000 - accuracy: 0.0000e+00 - val_loss: -400698168573952.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 146/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -187947148115968.0000 - accuracy: 0.0000e+00 - val_loss: -407816137342976.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 147/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -191275261231104.0000 - accuracy: 0.0000e+00 - val_loss: -415018965270528.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 148/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -194642280710144.0000 - accuracy: 0.0000e+00 - val_loss: -422304941080576.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 149/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -198047820677120.0000 - accuracy: 0.0000e+00 - val_loss: -429665441284096.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 150/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -201491176488960.0000 - accuracy: 0.0000e+00 - val_loss: -437115800256512.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 151/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -204970972413952.0000 - accuracy: 0.0000e+00 - val_loss: -444641723809792.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 152/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -208499220938752.0000 - accuracy: 0.0000e+00 - val_loss: -452285356310528.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 153/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -212069848711168.0000 - accuracy: 0.0000e+00 - val_loss: -459999687999488.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 154/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -215677419913216.0000 - accuracy: 0.0000e+00 - val_loss: -467803610021888.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 155/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -219326950932480.0000 - accuracy: 0.0000e+00 - val_loss: -475696350625792.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 156/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -223015958740992.0000 - accuracy: 0.0000e+00 - val_loss: -483671802904576.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 157/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -226743134715904.0000 - accuracy: 0.0000e+00 - val_loss: -491728054255616.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 158/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -230513025482752.0000 - accuracy: 0.0000e+00 - val_loss: -499893021966336.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 159/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -234322611142656.0000 - accuracy: 0.0000e+00 - val_loss: -508121373999104.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 160/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -238165717680128.0000 - accuracy: 0.0000e+00 - val_loss: -516429686243328.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 161/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -242059709513728.0000 - accuracy: 0.0000e+00 - val_loss: -524861545906176.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 162/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -246001180868608.0000 - accuracy: 0.0000e+00 - val_loss: -533386720444416.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 163/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -249986289762304.0000 - accuracy: 0.0000e+00 - val_loss: -541996485705728.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 164/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -254005187969024.0000 - accuracy: 0.0000e+00 - val_loss: -550686412505088.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 165/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -258067958595584.0000 - accuracy: 0.0000e+00 - val_loss: -559475022888960.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 166/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -262170206011392.0000 - accuracy: 0.0000e+00 - val_loss: -568328057782272.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 167/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -266316074188800.0000 - accuracy: 0.0000e+00 - val_loss: -577300781334528.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 168/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -270512576004096.0000 - accuracy: 0.0000e+00 - val_loss: -586382623899648.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 169/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -274749846454272.0000 - accuracy: 0.0000e+00 - val_loss: -595535132098560.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 170/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -279031442309120.0000 - accuracy: 0.0000e+00 - val_loss: -604801456930816.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 171/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -283355434188800.0000 - accuracy: 0.0000e+00 - val_loss: -614145359609856.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 172/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -287724858769408.0000 - accuracy: 0.0000e+00 - val_loss: -623591938850816.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 173/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -292138306764800.0000 - accuracy: 0.0000e+00 - val_loss: -633128041316352.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 174/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -296595308412928.0000 - accuracy: 0.0000e+00 - val_loss: -642765545275392.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 175/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -301095192625152.0000 - accuracy: 0.0000e+00 - val_loss: -652484452286464.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 176/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -305633966424064.0000 - accuracy: 0.0000e+00 - val_loss: -662292949630976.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 177/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -310217904488448.0000 - accuracy: 0.0000e+00 - val_loss: -672202177380352.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 178/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -314848919420928.0000 - accuracy: 0.0000e+00 - val_loss: -682218443767808.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 179/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1008/1008 [==============================] - 2s 2ms/step - loss: -319535366275072.0000 - accuracy: 0.0000e+00 - val_loss: -692341815902208.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 180/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -324265836544000.0000 - accuracy: 0.0000e+00 - val_loss: -702564710481920.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 181/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -329039726247936.0000 - accuracy: 0.0000e+00 - val_loss: -712881087709184.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 182/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -333860457938944.0000 - accuracy: 0.0000e+00 - val_loss: -723314569904128.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 183/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -338729373794304.0000 - accuracy: 0.0000e+00 - val_loss: -733826166816768.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 184/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -343644158558208.0000 - accuracy: 0.0000e+00 - val_loss: -744449835532288.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 185/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -348605852418048.0000 - accuracy: 0.0000e+00 - val_loss: -755165711826944.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 186/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -353614287601664.0000 - accuracy: 0.0000e+00 - val_loss: -766006746152960.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 187/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -358669698990080.0000 - accuracy: 0.0000e+00 - val_loss: -776915761758208.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 188/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -363773395206144.0000 - accuracy: 0.0000e+00 - val_loss: -787956243628032.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 189/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -368934637273088.0000 - accuracy: 0.0000e+00 - val_loss: -799109535498240.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 190/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -374142754881536.0000 - accuracy: 0.0000e+00 - val_loss: -810357786411008.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 191/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -379390265393152.0000 - accuracy: 0.0000e+00 - val_loss: -821693144629248.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 192/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -384681631547392.0000 - accuracy: 0.0000e+00 - val_loss: -833120106446848.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 193/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -390020879876096.0000 - accuracy: 0.0000e+00 - val_loss: -844660012482560.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 194/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -395419821539328.0000 - accuracy: 0.0000e+00 - val_loss: -856331116347392.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 195/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -400876040617984.0000 - accuracy: 0.0000e+00 - val_loss: -868131471884288.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 196/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -406382926888960.0000 - accuracy: 0.0000e+00 - val_loss: -880022961258496.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 197/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -411929407389696.0000 - accuracy: 0.0000e+00 - val_loss: -892002430353408.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 198/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -417530279624704.0000 - accuracy: 0.0000e+00 - val_loss: -904097863565312.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 199/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -423170645426176.0000 - accuracy: 0.0000e+00 - val_loss: -916282014695424.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 200/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -428870234800128.0000 - accuracy: 0.0000e+00 - val_loss: -928611120971776.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 201/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -434618947862528.0000 - accuracy: 0.0000e+00 - val_loss: -941021093429248.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 202/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -440411382349824.0000 - accuracy: 0.0000e+00 - val_loss: -953522468159488.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 203/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -446260054065152.0000 - accuracy: 0.0000e+00 - val_loss: -966166180790272.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 204/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -452152816304128.0000 - accuracy: 0.0000e+00 - val_loss: -978883377627136.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 205/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -458105271877632.0000 - accuracy: 0.0000e+00 - val_loss: -991757810532352.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 206/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -464114098896896.0000 - accuracy: 0.0000e+00 - val_loss: -1004742503301120.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 207/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -470163224788992.0000 - accuracy: 0.0000e+00 - val_loss: -1017790211293184.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 208/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -476264494268416.0000 - accuracy: 0.0000e+00 - val_loss: -1030985357459456.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 209/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -482425557745664.0000 - accuracy: 0.0000e+00 - val_loss: -1044295595327488.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 210/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -488633630982144.0000 - accuracy: 0.0000e+00 - val_loss: -1057693544480768.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 211/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -494900592246784.0000 - accuracy: 0.0000e+00 - val_loss: -1071232019595264.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 212/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -501216442318848.0000 - accuracy: 0.0000e+00 - val_loss: -1084856662491136.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 213/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -507578966605824.0000 - accuracy: 0.0000e+00 - val_loss: -1098610154405888.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 214/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -514005814738944.0000 - accuracy: 0.0000e+00 - val_loss: -1112495850782720.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 215/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -520489269198848.0000 - accuracy: 0.0000e+00 - val_loss: -1126512342335488.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 216/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -527034832912384.0000 - accuracy: 0.0000e+00 - val_loss: -1140649764061184.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 217/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -533621534359552.0000 - accuracy: 0.0000e+00 - val_loss: -1154860468666368.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 218/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -540262526877696.0000 - accuracy: 0.0000e+00 - val_loss: -1169213041410048.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 219/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -546962608750592.0000 - accuracy: 0.0000e+00 - val_loss: -1183683859972096.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 220/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -553714800656384.0000 - accuracy: 0.0000e+00 - val_loss: -1198263126458368.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 221/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -560514337865728.0000 - accuracy: 0.0000e+00 - val_loss: -1212945472159744.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 222/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -567365179801600.0000 - accuracy: 0.0000e+00 - val_loss: -1227726065238016.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 223/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1008/1008 [==============================] - 2s 2ms/step - loss: -574293029158912.0000 - accuracy: 0.0000e+00 - val_loss: -1242705032118272.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 224/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -581271277273088.0000 - accuracy: 0.0000e+00 - val_loss: -1257778890932224.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 225/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -588311802413056.0000 - accuracy: 0.0000e+00 - val_loss: -1272981196111872.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 226/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -595400310390784.0000 - accuracy: 0.0000e+00 - val_loss: -1288283896152064.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 227/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -602541901479936.0000 - accuracy: 0.0000e+00 - val_loss: -1303693433503744.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 228/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -609740065341440.0000 - accuracy: 0.0000e+00 - val_loss: -1319239201849344.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 229/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -616996144152576.0000 - accuracy: 0.0000e+00 - val_loss: -1334897847304192.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 230/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -624302286176256.0000 - accuracy: 0.0000e+00 - val_loss: -1350679436197888.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 231/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -631665672060928.0000 - accuracy: 0.0000e+00 - val_loss: -1366580881522688.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 232/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -639096703680512.0000 - accuracy: 0.0000e+00 - val_loss: -1382645401387008.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 233/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -646586522664960.0000 - accuracy: 0.0000e+00 - val_loss: -1398812060942336.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 234/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -654131639353344.0000 - accuracy: 0.0000e+00 - val_loss: -1415086363115520.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 235/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -661729100955648.0000 - accuracy: 0.0000e+00 - val_loss: -1431504949346304.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 236/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -669393268768768.0000 - accuracy: 0.0000e+00 - val_loss: -1448046210580480.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 237/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -677101728432128.0000 - accuracy: 0.0000e+00 - val_loss: -1464668807757824.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 238/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -684864277839872.0000 - accuracy: 0.0000e+00 - val_loss: -1481430320283648.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 239/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -692704807747584.0000 - accuracy: 0.0000e+00 - val_loss: -1498397320151040.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 240/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -700614325567488.0000 - accuracy: 0.0000e+00 - val_loss: -1515457332903936.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 241/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -708560686153728.0000 - accuracy: 0.0000e+00 - val_loss: -1532594252414976.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 242/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -716564357709824.0000 - accuracy: 0.0000e+00 - val_loss: -1549884180135936.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 243/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -724648962555904.0000 - accuracy: 0.0000e+00 - val_loss: -1567355436007424.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 244/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -732787388710912.0000 - accuracy: 0.0000e+00 - val_loss: -1584890982170624.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 245/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -740986883932160.0000 - accuracy: 0.0000e+00 - val_loss: -1602610406621184.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 246/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -749249998356480.0000 - accuracy: 0.0000e+00 - val_loss: -1620445258317824.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 247/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -757568477593600.0000 - accuracy: 0.0000e+00 - val_loss: -1638413388218368.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 248/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -765959769948160.0000 - accuracy: 0.0000e+00 - val_loss: -1656518420201472.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 249/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -774399783337984.0000 - accuracy: 0.0000e+00 - val_loss: -1674731363237888.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 250/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -782889255960576.0000 - accuracy: 0.0000e+00 - val_loss: -1693040674603008.0000 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "history=model.fit(X_amb, Y2_amb, validation_split=0.33, epochs=250, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640b7af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "# model.fit(X1, Y1, validation_split=0.33, epochs=250, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ac2c003b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-28T12:38:51.378873Z",
     "start_time": "2022-06-28T12:38:50.765939Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "470/470 [==============================] - 1s 1ms/step - loss: -1086106766409728.0000 - accuracy: 0.0000e+00\n",
      "[-1086106766409728.0, 0.0]\n",
      "accuracy: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(X_amb, Y2_amb)\n",
    "print(scores)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "25df3cc6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-28T12:38:59.411245Z",
     "start_time": "2022-06-28T12:38:59.378213Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [-470709501952.0,\n",
       "  -539605893120.0,\n",
       "  -614623215616.0,\n",
       "  -695949787136.0,\n",
       "  -783749349376.0,\n",
       "  -878327693312.0,\n",
       "  -980101955584.0,\n",
       "  -1089218347008.0,\n",
       "  -1205689516032.0,\n",
       "  -1329908023296.0,\n",
       "  -1462190997504.0,\n",
       "  -1602743959552.0,\n",
       "  -1751690510336.0,\n",
       "  -1909372616704.0,\n",
       "  -2075779530752.0,\n",
       "  -2251165532160.0,\n",
       "  -2435773628416.0,\n",
       "  -2630416596992.0,\n",
       "  -2834782224384.0,\n",
       "  -3049118498816.0,\n",
       "  -3273677602816.0,\n",
       "  -3509136130048.0,\n",
       "  -3755118166016.0,\n",
       "  -4012189679616.0,\n",
       "  -4280084594688.0,\n",
       "  -4559752658944.0,\n",
       "  -4851408306176.0,\n",
       "  -5155146170368.0,\n",
       "  -5470761254912.0,\n",
       "  -5798484246528.0,\n",
       "  -6138821607424.0,\n",
       "  -6491843592192.0,\n",
       "  -6858417897472.0,\n",
       "  -7237903319040.0,\n",
       "  -7630593982464.0,\n",
       "  -8037111693312.0,\n",
       "  -8457830793216.0,\n",
       "  -8892688891904.0,\n",
       "  -9341620977664.0,\n",
       "  -9805736443904.0,\n",
       "  -10284722814976.0,\n",
       "  -10777731792896.0,\n",
       "  -11286489333760.0,\n",
       "  -11810480586752.0,\n",
       "  -12350616764416.0,\n",
       "  -12907628724224.0,\n",
       "  -13480635662336.0,\n",
       "  -14069895528448.0,\n",
       "  -14676077314048.0,\n",
       "  -15298875883520.0,\n",
       "  -15937578205184.0,\n",
       "  -16593736171520.0,\n",
       "  -17267982073856.0,\n",
       "  -17960909406208.0,\n",
       "  -18672133341184.0,\n",
       "  -19401568944128.0,\n",
       "  -20148863893504.0,\n",
       "  -20914582323200.0,\n",
       "  -21700076896256.0,\n",
       "  -22504175304704.0,\n",
       "  -23327148081152.0,\n",
       "  -24169859252224.0,\n",
       "  -25033369976832.0,\n",
       "  -25916795256832.0,\n",
       "  -26820231561216.0,\n",
       "  -27745817985024.0,\n",
       "  -28690769510400.0,\n",
       "  -29657453821952.0,\n",
       "  -30642496602112.0,\n",
       "  -31649049870336.0,\n",
       "  -32678399180800.0,\n",
       "  -33729368031232.0,\n",
       "  -34803114049536.0,\n",
       "  -35899303788544.0,\n",
       "  -37018046300160.0,\n",
       "  -38159018622976.0,\n",
       "  -39323567128576.0,\n",
       "  -40512086081536.0,\n",
       "  -41722323140608.0,\n",
       "  -42956027330560.0,\n",
       "  -44214666657792.0,\n",
       "  -45497708445696.0,\n",
       "  -46804603240448.0,\n",
       "  -48135338459136.0,\n",
       "  -49492539736064.0,\n",
       "  -50874667761664.0,\n",
       "  -52280648794112.0,\n",
       "  -53713272045568.0,\n",
       "  -55171526688768.0,\n",
       "  -56655651799040.0,\n",
       "  -58165655764992.0,\n",
       "  -59700796194816.0,\n",
       "  -61262390099968.0,\n",
       "  -62851813212160.0,\n",
       "  -64468990033920.0,\n",
       "  -66110699339776.0,\n",
       "  -67779495460864.0,\n",
       "  -69476242423808.0,\n",
       "  -71204064985088.0,\n",
       "  -72958533959680.0,\n",
       "  -74742405005312.0,\n",
       "  -76555418075136.0,\n",
       "  -78395962556416.0,\n",
       "  -80263115702272.0,\n",
       "  -82162464325632.0,\n",
       "  -84090149666816.0,\n",
       "  -86047815892992.0,\n",
       "  -88032510214144.0,\n",
       "  -90048502431744.0,\n",
       "  -92097151500288.0,\n",
       "  -94175722733568.0,\n",
       "  -96283419213824.0,\n",
       "  -98423445389312.0,\n",
       "  -100595843203072.0,\n",
       "  -102799807348736.0,\n",
       "  -105036570951680.0,\n",
       "  -107305739747328.0,\n",
       "  -109604486774784.0,\n",
       "  -111934531698688.0,\n",
       "  -114295866130432.0,\n",
       "  -116694336929792.0,\n",
       "  -119126362161152.0,\n",
       "  -121586145296384.0,\n",
       "  -124081949114368.0,\n",
       "  -126614243377152.0,\n",
       "  -129180368896000.0,\n",
       "  -131779159654400.0,\n",
       "  -134412620529664.0,\n",
       "  -137080759910400.0,\n",
       "  -139781799411712.0,\n",
       "  -142516007469056.0,\n",
       "  -145290304684032.0,\n",
       "  -148096025624576.0,\n",
       "  -150940686483456.0,\n",
       "  -153823968493568.0,\n",
       "  -156738942664704.0,\n",
       "  -159686649184256.0,\n",
       "  -162673882824704.0,\n",
       "  -165698160558080.0,\n",
       "  -168766226825216.0,\n",
       "  -171869542023168.0,\n",
       "  -175007988711424.0,\n",
       "  -178188797870080.0,\n",
       "  -181404939845632.0,\n",
       "  -184655827435520.0,\n",
       "  -187947148115968.0,\n",
       "  -191275261231104.0,\n",
       "  -194642280710144.0,\n",
       "  -198047820677120.0,\n",
       "  -201491176488960.0,\n",
       "  -204970972413952.0,\n",
       "  -208499220938752.0,\n",
       "  -212069848711168.0,\n",
       "  -215677419913216.0,\n",
       "  -219326950932480.0,\n",
       "  -223015958740992.0,\n",
       "  -226743134715904.0,\n",
       "  -230513025482752.0,\n",
       "  -234322611142656.0,\n",
       "  -238165717680128.0,\n",
       "  -242059709513728.0,\n",
       "  -246001180868608.0,\n",
       "  -249986289762304.0,\n",
       "  -254005187969024.0,\n",
       "  -258067958595584.0,\n",
       "  -262170206011392.0,\n",
       "  -266316074188800.0,\n",
       "  -270512576004096.0,\n",
       "  -274749846454272.0,\n",
       "  -279031442309120.0,\n",
       "  -283355434188800.0,\n",
       "  -287724858769408.0,\n",
       "  -292138306764800.0,\n",
       "  -296595308412928.0,\n",
       "  -301095192625152.0,\n",
       "  -305633966424064.0,\n",
       "  -310217904488448.0,\n",
       "  -314848919420928.0,\n",
       "  -319535366275072.0,\n",
       "  -324265836544000.0,\n",
       "  -329039726247936.0,\n",
       "  -333860457938944.0,\n",
       "  -338729373794304.0,\n",
       "  -343644158558208.0,\n",
       "  -348605852418048.0,\n",
       "  -353614287601664.0,\n",
       "  -358669698990080.0,\n",
       "  -363773395206144.0,\n",
       "  -368934637273088.0,\n",
       "  -374142754881536.0,\n",
       "  -379390265393152.0,\n",
       "  -384681631547392.0,\n",
       "  -390020879876096.0,\n",
       "  -395419821539328.0,\n",
       "  -400876040617984.0,\n",
       "  -406382926888960.0,\n",
       "  -411929407389696.0,\n",
       "  -417530279624704.0,\n",
       "  -423170645426176.0,\n",
       "  -428870234800128.0,\n",
       "  -434618947862528.0,\n",
       "  -440411382349824.0,\n",
       "  -446260054065152.0,\n",
       "  -452152816304128.0,\n",
       "  -458105271877632.0,\n",
       "  -464114098896896.0,\n",
       "  -470163224788992.0,\n",
       "  -476264494268416.0,\n",
       "  -482425557745664.0,\n",
       "  -488633630982144.0,\n",
       "  -494900592246784.0,\n",
       "  -501216442318848.0,\n",
       "  -507578966605824.0,\n",
       "  -514005814738944.0,\n",
       "  -520489269198848.0,\n",
       "  -527034832912384.0,\n",
       "  -533621534359552.0,\n",
       "  -540262526877696.0,\n",
       "  -546962608750592.0,\n",
       "  -553714800656384.0,\n",
       "  -560514337865728.0,\n",
       "  -567365179801600.0,\n",
       "  -574293029158912.0,\n",
       "  -581271277273088.0,\n",
       "  -588311802413056.0,\n",
       "  -595400310390784.0,\n",
       "  -602541901479936.0,\n",
       "  -609740065341440.0,\n",
       "  -616996144152576.0,\n",
       "  -624302286176256.0,\n",
       "  -631665672060928.0,\n",
       "  -639096703680512.0,\n",
       "  -646586522664960.0,\n",
       "  -654131639353344.0,\n",
       "  -661729100955648.0,\n",
       "  -669393268768768.0,\n",
       "  -677101728432128.0,\n",
       "  -684864277839872.0,\n",
       "  -692704807747584.0,\n",
       "  -700614325567488.0,\n",
       "  -708560686153728.0,\n",
       "  -716564357709824.0,\n",
       "  -724648962555904.0,\n",
       "  -732787388710912.0,\n",
       "  -740986883932160.0,\n",
       "  -749249998356480.0,\n",
       "  -757568477593600.0,\n",
       "  -765959769948160.0,\n",
       "  -774399783337984.0,\n",
       "  -782889255960576.0],\n",
       " 'accuracy': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " 'val_loss': [-1084698591232.0,\n",
       "  -1239454580736.0,\n",
       "  -1407506841600.0,\n",
       "  -1589559689216.0,\n",
       "  -1785468289024.0,\n",
       "  -1996389744640.0,\n",
       "  -2223530573824.0,\n",
       "  -2465888993280.0,\n",
       "  -2724575838208.0,\n",
       "  -3000229167104.0,\n",
       "  -3293849059328.0,\n",
       "  -3605364998144.0,\n",
       "  -3935006621696.0,\n",
       "  -4283627470848.0,\n",
       "  -4650964090880.0,\n",
       "  -5038191149056.0,\n",
       "  -5445759533056.0,\n",
       "  -5874907086848.0,\n",
       "  -6325180301312.0,\n",
       "  -6796992315392.0,\n",
       "  -7291344519168.0,\n",
       "  -7809680801792.0,\n",
       "  -8349932322816.0,\n",
       "  -8915604471808.0,\n",
       "  -9503421497344.0,\n",
       "  -10118010765312.0,\n",
       "  -10758974865408.0,\n",
       "  -11424328843264.0,\n",
       "  -12116580892672.0,\n",
       "  -12834357379072.0,\n",
       "  -13580763136000.0,\n",
       "  -14353933795328.0,\n",
       "  -15156824244224.0,\n",
       "  -15987278610432.0,\n",
       "  -16845736247296.0,\n",
       "  -17736012922880.0,\n",
       "  -18656153042944.0,\n",
       "  -19607031119872.0,\n",
       "  -20587512594432.0,\n",
       "  -21602232172544.0,\n",
       "  -22648543248384.0,\n",
       "  -23725929922560.0,\n",
       "  -24836264951808.0,\n",
       "  -25980049555456.0,\n",
       "  -27159749984256.0,\n",
       "  -28375362043904.0,\n",
       "  -29625390465024.0,\n",
       "  -30910405672960.0,\n",
       "  -32233737945088.0,\n",
       "  -33589638987776.0,\n",
       "  -34979992043520.0,\n",
       "  -36412866953216.0,\n",
       "  -37882538491904.0,\n",
       "  -39392760561664.0,\n",
       "  -40941679280128.0,\n",
       "  -42529756020736.0,\n",
       "  -44158764974080.0,\n",
       "  -45825304559616.0,\n",
       "  -47534772846592.0,\n",
       "  -49284040884224.0,\n",
       "  -51076707385344.0,\n",
       "  -52910608089088.0,\n",
       "  -54790558056448.0,\n",
       "  -56711742226432.0,\n",
       "  -58678971465728.0,\n",
       "  -60690303811584.0,\n",
       "  -62744988483584.0,\n",
       "  -64847316254720.0,\n",
       "  -66985102671872.0,\n",
       "  -69176198692864.0,\n",
       "  -71413302034432.0,\n",
       "  -73697536770048.0,\n",
       "  -76031465619456.0,\n",
       "  -78413855457280.0,\n",
       "  -80844186189824.0,\n",
       "  -83321853837312.0,\n",
       "  -85852512321536.0,\n",
       "  -88433687003136.0,\n",
       "  -91062131490816.0,\n",
       "  -93740362366976.0,\n",
       "  -96476340420608.0,\n",
       "  -99258539704320.0,\n",
       "  -102098595217408.0,\n",
       "  -104985366888448.0,\n",
       "  -107934851792896.0,\n",
       "  -110931640057856.0,\n",
       "  -113984967540736.0,\n",
       "  -117092258938880.0,\n",
       "  -120259000401920.0,\n",
       "  -123475620528128.0,\n",
       "  -126754559623168.0,\n",
       "  -130081867431936.0,\n",
       "  -133471183831040.0,\n",
       "  -136918247407616.0,\n",
       "  -140426136780800.0,\n",
       "  -143984986947584.0,\n",
       "  -147605409497088.0,\n",
       "  -151288796938240.0,\n",
       "  -155032330698752.0,\n",
       "  -158836430209024.0,\n",
       "  -162705826643968.0,\n",
       "  -166636208259072.0,\n",
       "  -170621468147712.0,\n",
       "  -174669323829248.0,\n",
       "  -178789086658560.0,\n",
       "  -182964231077888.0,\n",
       "  -187208799617024.0,\n",
       "  -191510863675392.0,\n",
       "  -195876144283648.0,\n",
       "  -200320294584320.0,\n",
       "  -204820547895296.0,\n",
       "  -209387138318336.0,\n",
       "  -214021357699072.0,\n",
       "  -218733020708864.0,\n",
       "  -223504108617728.0,\n",
       "  -228352623378432.0,\n",
       "  -233268347666432.0,\n",
       "  -238244620926976.0,\n",
       "  -243290519633920.0,\n",
       "  -248405473361920.0,\n",
       "  -253599951093760.0,\n",
       "  -258867745259520.0,\n",
       "  -264188219883520.0,\n",
       "  -269601120190464.0,\n",
       "  -275081364242432.0,\n",
       "  -280639018369024.0,\n",
       "  -286259704496128.0,\n",
       "  -291963152629760.0,\n",
       "  -297741662027776.0,\n",
       "  -303582582669312.0,\n",
       "  -309507490054144.0,\n",
       "  -315512324096000.0,\n",
       "  -321582186627072.0,\n",
       "  -327744692944896.0,\n",
       "  -333981924982784.0,\n",
       "  -340284353282048.0,\n",
       "  -346664158101504.0,\n",
       "  -353132009750528.0,\n",
       "  -359673010061312.0,\n",
       "  -366327055253504.0,\n",
       "  -373033680240640.0,\n",
       "  -379830231105536.0,\n",
       "  -386709359427584.0,\n",
       "  -393663146360832.0,\n",
       "  -400698168573952.0,\n",
       "  -407816137342976.0,\n",
       "  -415018965270528.0,\n",
       "  -422304941080576.0,\n",
       "  -429665441284096.0,\n",
       "  -437115800256512.0,\n",
       "  -444641723809792.0,\n",
       "  -452285356310528.0,\n",
       "  -459999687999488.0,\n",
       "  -467803610021888.0,\n",
       "  -475696350625792.0,\n",
       "  -483671802904576.0,\n",
       "  -491728054255616.0,\n",
       "  -499893021966336.0,\n",
       "  -508121373999104.0,\n",
       "  -516429686243328.0,\n",
       "  -524861545906176.0,\n",
       "  -533386720444416.0,\n",
       "  -541996485705728.0,\n",
       "  -550686412505088.0,\n",
       "  -559475022888960.0,\n",
       "  -568328057782272.0,\n",
       "  -577300781334528.0,\n",
       "  -586382623899648.0,\n",
       "  -595535132098560.0,\n",
       "  -604801456930816.0,\n",
       "  -614145359609856.0,\n",
       "  -623591938850816.0,\n",
       "  -633128041316352.0,\n",
       "  -642765545275392.0,\n",
       "  -652484452286464.0,\n",
       "  -662292949630976.0,\n",
       "  -672202177380352.0,\n",
       "  -682218443767808.0,\n",
       "  -692341815902208.0,\n",
       "  -702564710481920.0,\n",
       "  -712881087709184.0,\n",
       "  -723314569904128.0,\n",
       "  -733826166816768.0,\n",
       "  -744449835532288.0,\n",
       "  -755165711826944.0,\n",
       "  -766006746152960.0,\n",
       "  -776915761758208.0,\n",
       "  -787956243628032.0,\n",
       "  -799109535498240.0,\n",
       "  -810357786411008.0,\n",
       "  -821693144629248.0,\n",
       "  -833120106446848.0,\n",
       "  -844660012482560.0,\n",
       "  -856331116347392.0,\n",
       "  -868131471884288.0,\n",
       "  -880022961258496.0,\n",
       "  -892002430353408.0,\n",
       "  -904097863565312.0,\n",
       "  -916282014695424.0,\n",
       "  -928611120971776.0,\n",
       "  -941021093429248.0,\n",
       "  -953522468159488.0,\n",
       "  -966166180790272.0,\n",
       "  -978883377627136.0,\n",
       "  -991757810532352.0,\n",
       "  -1004742503301120.0,\n",
       "  -1017790211293184.0,\n",
       "  -1030985357459456.0,\n",
       "  -1044295595327488.0,\n",
       "  -1057693544480768.0,\n",
       "  -1071232019595264.0,\n",
       "  -1084856662491136.0,\n",
       "  -1098610154405888.0,\n",
       "  -1112495850782720.0,\n",
       "  -1126512342335488.0,\n",
       "  -1140649764061184.0,\n",
       "  -1154860468666368.0,\n",
       "  -1169213041410048.0,\n",
       "  -1183683859972096.0,\n",
       "  -1198263126458368.0,\n",
       "  -1212945472159744.0,\n",
       "  -1227726065238016.0,\n",
       "  -1242705032118272.0,\n",
       "  -1257778890932224.0,\n",
       "  -1272981196111872.0,\n",
       "  -1288283896152064.0,\n",
       "  -1303693433503744.0,\n",
       "  -1319239201849344.0,\n",
       "  -1334897847304192.0,\n",
       "  -1350679436197888.0,\n",
       "  -1366580881522688.0,\n",
       "  -1382645401387008.0,\n",
       "  -1398812060942336.0,\n",
       "  -1415086363115520.0,\n",
       "  -1431504949346304.0,\n",
       "  -1448046210580480.0,\n",
       "  -1464668807757824.0,\n",
       "  -1481430320283648.0,\n",
       "  -1498397320151040.0,\n",
       "  -1515457332903936.0,\n",
       "  -1532594252414976.0,\n",
       "  -1549884180135936.0,\n",
       "  -1567355436007424.0,\n",
       "  -1584890982170624.0,\n",
       "  -1602610406621184.0,\n",
       "  -1620445258317824.0,\n",
       "  -1638413388218368.0,\n",
       "  -1656518420201472.0,\n",
       "  -1674731363237888.0,\n",
       "  -1693040674603008.0],\n",
       " 'val_accuracy': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0]}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8694486d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-28T12:39:09.695927Z",
     "start_time": "2022-06-28T12:39:09.674090Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize training history\n",
    "\n",
    "# list all data in history\n",
    "model.history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "86851433",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-28T12:39:12.844097Z",
     "start_time": "2022-06-28T12:39:12.587236Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "03da9ecf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-28T12:45:09.588111Z",
     "start_time": "2022-06-28T12:45:09.571508Z"
    }
   },
   "outputs": [],
   "source": [
    "X_org = gas_turbine[:,0:3]\n",
    "Y_org = gas_turbine[:,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "04d085c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-28T12:45:10.798881Z",
     "start_time": "2022-06-28T12:45:10.785859Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   6.8594, 1007.9   ,   96.799 ],\n",
       "       [   6.785 , 1008.4   ,   97.118 ],\n",
       "       [   6.8977, 1008.8   ,   95.939 ],\n",
       "       ...,\n",
       "       [   7.2647, 1006.3   ,   99.496 ],\n",
       "       [   7.006 , 1006.8   ,   99.008 ],\n",
       "       [   6.9279, 1007.2   ,   97.533 ]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_org\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "73fec0c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-28T12:45:14.005432Z",
     "start_time": "2022-06-28T12:45:13.996107Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([114.7 , 114.72, 114.71, ..., 110.19, 110.74, 111.58])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "047d126d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-28T12:46:39.862695Z",
     "start_time": "2022-06-28T12:46:39.811018Z"
    }
   },
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=3,activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "532883fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-28T12:46:40.750980Z",
     "start_time": "2022-06-28T12:46:40.723768Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8ca8cac6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-28T12:55:40.498738Z",
     "start_time": "2022-06-28T12:46:41.528512Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 743.1392 - accuracy: 0.0000e+00 - val_loss: -131.4570 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -202.3967 - accuracy: 0.0000e+00 - val_loss: -263.4266 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -337.6779 - accuracy: 0.0000e+00 - val_loss: -395.3212 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -472.9160 - accuracy: 0.0000e+00 - val_loss: -527.1885 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -608.1356 - accuracy: 0.0000e+00 - val_loss: -659.0608 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -743.4451 - accuracy: 0.0000e+00 - val_loss: -791.0284 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -878.7549 - accuracy: 0.0000e+00 - val_loss: -922.9367 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -1014.0285 - accuracy: 0.0000e+00 - val_loss: -1054.8373 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -1149.2604 - accuracy: 0.0000e+00 - val_loss: -1186.6937 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -1284.5332 - accuracy: 0.0000e+00 - val_loss: -1318.6483 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -1419.8199 - accuracy: 0.0000e+00 - val_loss: -1450.5599 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -1555.0890 - accuracy: 0.0000e+00 - val_loss: -1582.4213 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -1690.3251 - accuracy: 0.0000e+00 - val_loss: -1714.3162 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/250\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -1825.5481 - accuracy: 0.0000e+00 - val_loss: -1846.1733 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/250\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -1960.8069 - accuracy: 0.0000e+00 - val_loss: -1978.1056 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -2096.0730 - accuracy: 0.0000e+00 - val_loss: -2109.9915 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -2231.3696 - accuracy: 0.0000e+00 - val_loss: -2241.9436 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -2366.6753 - accuracy: 0.0000e+00 - val_loss: -2373.8596 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -2501.9487 - accuracy: 0.0000e+00 - val_loss: -2505.7688 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -2637.2200 - accuracy: 0.0000e+00 - val_loss: -2637.6731 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -2772.4441 - accuracy: 0.0000e+00 - val_loss: -2769.5020 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -2907.7336 - accuracy: 0.0000e+00 - val_loss: -2901.4758 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -3043.0120 - accuracy: 0.0000e+00 - val_loss: -3033.3525 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -3178.2656 - accuracy: 0.0000e+00 - val_loss: -3165.2720 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -3313.5474 - accuracy: 0.0000e+00 - val_loss: -3297.1895 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -3448.8264 - accuracy: 0.0000e+00 - val_loss: -3429.0925 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -3584.0735 - accuracy: 0.0000e+00 - val_loss: -3560.9810 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -3719.3501 - accuracy: 0.0000e+00 - val_loss: -3692.9026 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/250\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -3854.6184 - accuracy: 0.0000e+00 - val_loss: -3824.7998 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -3989.8679 - accuracy: 0.0000e+00 - val_loss: -3956.6604 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/250\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -4125.1372 - accuracy: 0.0000e+00 - val_loss: -4088.5771 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -4260.4165 - accuracy: 0.0000e+00 - val_loss: -4220.5068 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -4395.7231 - accuracy: 0.0000e+00 - val_loss: -4352.4331 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -4531.0059 - accuracy: 0.0000e+00 - val_loss: -4484.3701 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -4666.2729 - accuracy: 0.0000e+00 - val_loss: -4616.2373 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -4801.5039 - accuracy: 0.0000e+00 - val_loss: -4748.1094 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -4936.7729 - accuracy: 0.0000e+00 - val_loss: -4880.0576 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/250\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -5072.0479 - accuracy: 0.0000e+00 - val_loss: -5011.9272 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/250\n",
      "1008/1008 [==============================] - 5s 5ms/step - loss: -5207.2769 - accuracy: 0.0000e+00 - val_loss: -5143.8066 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -5342.5645 - accuracy: 0.0000e+00 - val_loss: -5275.7427 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -5477.9019 - accuracy: 0.0000e+00 - val_loss: -5407.7241 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -5613.1636 - accuracy: 0.0000e+00 - val_loss: -5539.5737 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -5748.4067 - accuracy: 0.0000e+00 - val_loss: -5671.4756 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -5883.6543 - accuracy: 0.0000e+00 - val_loss: -5803.3643 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -6018.9033 - accuracy: 0.0000e+00 - val_loss: -5935.2642 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -6154.1860 - accuracy: 0.0000e+00 - val_loss: -6067.1738 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -6289.4253 - accuracy: 0.0000e+00 - val_loss: -6199.0322 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -6424.7109 - accuracy: 0.0000e+00 - val_loss: -6330.9956 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/250\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -6559.9712 - accuracy: 0.0000e+00 - val_loss: -6462.8555 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/250\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -6695.2388 - accuracy: 0.0000e+00 - val_loss: -6594.7754 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -6830.5239 - accuracy: 0.0000e+00 - val_loss: -6726.6851 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -6965.7729 - accuracy: 0.0000e+00 - val_loss: -6858.5532 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -7101.0244 - accuracy: 0.0000e+00 - val_loss: -6990.4673 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -7236.3032 - accuracy: 0.0000e+00 - val_loss: -7122.3726 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -7371.5459 - accuracy: 0.0000e+00 - val_loss: -7254.2544 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -7506.8613 - accuracy: 0.0000e+00 - val_loss: -7386.2212 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -7642.1519 - accuracy: 0.0000e+00 - val_loss: -7518.1245 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -7777.4194 - accuracy: 0.0000e+00 - val_loss: -7650.0537 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/250\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -7912.6719 - accuracy: 0.0000e+00 - val_loss: -7781.9458 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -8047.9736 - accuracy: 0.0000e+00 - val_loss: -7913.8657 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/250\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -8183.2769 - accuracy: 0.0000e+00 - val_loss: -8045.7725 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -8318.5244 - accuracy: 0.0000e+00 - val_loss: -8177.6851 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -8453.7900 - accuracy: 0.0000e+00 - val_loss: -8309.5693 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -8589.0811 - accuracy: 0.0000e+00 - val_loss: -8441.5234 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -8724.3486 - accuracy: 0.0000e+00 - val_loss: -8573.4033 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -8859.6396 - accuracy: 0.0000e+00 - val_loss: -8705.3584 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -8994.8740 - accuracy: 0.0000e+00 - val_loss: -8837.1748 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -9130.0771 - accuracy: 0.0000e+00 - val_loss: -8969.0566 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -9265.3516 - accuracy: 0.0000e+00 - val_loss: -9100.9434 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -9400.5928 - accuracy: 0.0000e+00 - val_loss: -9232.8281 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -9535.9043 - accuracy: 0.0000e+00 - val_loss: -9364.7676 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/250\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -9671.1953 - accuracy: 0.0000e+00 - val_loss: -9496.7217 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -9806.4619 - accuracy: 0.0000e+00 - val_loss: -9628.6074 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -9941.7598 - accuracy: 0.0000e+00 - val_loss: -9760.5576 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -10077.0244 - accuracy: 0.0000e+00 - val_loss: -9892.4180 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -10212.2637 - accuracy: 0.0000e+00 - val_loss: -10024.3174 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -10347.5479 - accuracy: 0.0000e+00 - val_loss: -10156.2295 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -10482.7959 - accuracy: 0.0000e+00 - val_loss: -10288.1084 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -10618.0918 - accuracy: 0.0000e+00 - val_loss: -10420.0723 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -10753.3633 - accuracy: 0.0000e+00 - val_loss: -10551.9600 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -10888.6104 - accuracy: 0.0000e+00 - val_loss: -10683.8145 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -11023.8506 - accuracy: 0.0000e+00 - val_loss: -10815.6914 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -11159.1084 - accuracy: 0.0000e+00 - val_loss: -10947.6133 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -11294.4180 - accuracy: 0.0000e+00 - val_loss: -11079.5732 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -11429.6807 - accuracy: 0.0000e+00 - val_loss: -11211.4189 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -11564.8945 - accuracy: 0.0000e+00 - val_loss: -11343.3193 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -11700.1621 - accuracy: 0.0000e+00 - val_loss: -11475.2139 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -11835.4678 - accuracy: 0.0000e+00 - val_loss: -11607.1768 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/250\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -11970.7402 - accuracy: 0.0000e+00 - val_loss: -11739.0566 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/250\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -12106.0117 - accuracy: 0.0000e+00 - val_loss: -11870.9971 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -12241.2637 - accuracy: 0.0000e+00 - val_loss: -12002.8564 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -12376.5820 - accuracy: 0.0000e+00 - val_loss: -12134.8086 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -12511.8574 - accuracy: 0.0000e+00 - val_loss: -12266.6953 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -12647.1230 - accuracy: 0.0000e+00 - val_loss: -12398.6221 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -12782.3799 - accuracy: 0.0000e+00 - val_loss: -12530.4717 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -12917.6279 - accuracy: 0.0000e+00 - val_loss: -12662.4062 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -13052.8848 - accuracy: 0.0000e+00 - val_loss: -12794.2930 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/250\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -13188.1963 - accuracy: 0.0000e+00 - val_loss: -12926.2539 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -13323.4570 - accuracy: 0.0000e+00 - val_loss: -13058.1064 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -13458.7041 - accuracy: 0.0000e+00 - val_loss: -13190.0029 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -13594.0010 - accuracy: 0.0000e+00 - val_loss: -13321.9570 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1008/1008 [==============================] - 2s 2ms/step - loss: -13729.3018 - accuracy: 0.0000e+00 - val_loss: -13453.8848 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -13864.5557 - accuracy: 0.0000e+00 - val_loss: -13585.7520 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -13999.7852 - accuracy: 0.0000e+00 - val_loss: -13717.6270 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -14135.0381 - accuracy: 0.0000e+00 - val_loss: -13849.5234 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -14270.3359 - accuracy: 0.0000e+00 - val_loss: -13981.4785 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -14405.5947 - accuracy: 0.0000e+00 - val_loss: -14113.3359 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -14540.8262 - accuracy: 0.0000e+00 - val_loss: -14245.2354 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -14676.1084 - accuracy: 0.0000e+00 - val_loss: -14377.1514 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -14811.4248 - accuracy: 0.0000e+00 - val_loss: -14509.0840 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -14946.7090 - accuracy: 0.0000e+00 - val_loss: -14641.0059 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -15081.9736 - accuracy: 0.0000e+00 - val_loss: -14772.9248 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -15217.2500 - accuracy: 0.0000e+00 - val_loss: -14904.7998 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -15352.4873 - accuracy: 0.0000e+00 - val_loss: -15036.6631 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -15487.7441 - accuracy: 0.0000e+00 - val_loss: -15168.5820 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -15623.0254 - accuracy: 0.0000e+00 - val_loss: -15300.5166 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -15758.2949 - accuracy: 0.0000e+00 - val_loss: -15432.4043 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -15893.5371 - accuracy: 0.0000e+00 - val_loss: -15564.2666 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -16028.8086 - accuracy: 0.0000e+00 - val_loss: -15696.2012 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -16164.0381 - accuracy: 0.0000e+00 - val_loss: -15828.0781 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -16299.3232 - accuracy: 0.0000e+00 - val_loss: -15960.0176 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -16434.6211 - accuracy: 0.0000e+00 - val_loss: -16091.9170 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -16569.9062 - accuracy: 0.0000e+00 - val_loss: -16223.8369 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -16705.1680 - accuracy: 0.0000e+00 - val_loss: -16355.7559 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -16840.4883 - accuracy: 0.0000e+00 - val_loss: -16487.7012 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -16975.7812 - accuracy: 0.0000e+00 - val_loss: -16619.6465 - val_accuracy: 0.0000e+00\n",
      "Epoch 127/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -17111.0527 - accuracy: 0.0000e+00 - val_loss: -16751.5156 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -17246.2949 - accuracy: 0.0000e+00 - val_loss: -16883.4180 - val_accuracy: 0.0000e+00\n",
      "Epoch 129/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -17381.6016 - accuracy: 0.0000e+00 - val_loss: -17015.3418 - val_accuracy: 0.0000e+00\n",
      "Epoch 130/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -17516.8691 - accuracy: 0.0000e+00 - val_loss: -17147.2539 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -17652.1152 - accuracy: 0.0000e+00 - val_loss: -17279.1094 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -17787.3418 - accuracy: 0.0000e+00 - val_loss: -17411.0098 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -17922.6074 - accuracy: 0.0000e+00 - val_loss: -17542.8691 - val_accuracy: 0.0000e+00\n",
      "Epoch 134/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -18057.8809 - accuracy: 0.0000e+00 - val_loss: -17674.7949 - val_accuracy: 0.0000e+00\n",
      "Epoch 135/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -18193.1758 - accuracy: 0.0000e+00 - val_loss: -17806.7520 - val_accuracy: 0.0000e+00\n",
      "Epoch 136/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -18328.4941 - accuracy: 0.0000e+00 - val_loss: -17938.6934 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -18463.7480 - accuracy: 0.0000e+00 - val_loss: -18070.5352 - val_accuracy: 0.0000e+00\n",
      "Epoch 138/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -18598.9766 - accuracy: 0.0000e+00 - val_loss: -18202.4297 - val_accuracy: 0.0000e+00\n",
      "Epoch 139/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -18734.2656 - accuracy: 0.0000e+00 - val_loss: -18334.3711 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -18869.5703 - accuracy: 0.0000e+00 - val_loss: -18466.3027 - val_accuracy: 0.0000e+00\n",
      "Epoch 141/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -19004.8242 - accuracy: 0.0000e+00 - val_loss: -18598.1953 - val_accuracy: 0.0000e+00\n",
      "Epoch 142/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -19140.1074 - accuracy: 0.0000e+00 - val_loss: -18730.0801 - val_accuracy: 0.0000e+00\n",
      "Epoch 143/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -19275.3672 - accuracy: 0.0000e+00 - val_loss: -18862.0117 - val_accuracy: 0.0000e+00\n",
      "Epoch 144/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -19410.6289 - accuracy: 0.0000e+00 - val_loss: -18993.8984 - val_accuracy: 0.0000e+00\n",
      "Epoch 145/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -19545.8887 - accuracy: 0.0000e+00 - val_loss: -19125.8125 - val_accuracy: 0.0000e+00\n",
      "Epoch 146/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -19681.1660 - accuracy: 0.0000e+00 - val_loss: -19257.7246 - val_accuracy: 0.0000e+00\n",
      "Epoch 147/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -19816.4434 - accuracy: 0.0000e+00 - val_loss: -19389.6484 - val_accuracy: 0.0000e+00\n",
      "Epoch 148/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -19951.7402 - accuracy: 0.0000e+00 - val_loss: -19521.5566 - val_accuracy: 0.0000e+00\n",
      "Epoch 149/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -20086.9512 - accuracy: 0.0000e+00 - val_loss: -19653.3516 - val_accuracy: 0.0000e+00\n",
      "Epoch 150/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -20222.1523 - accuracy: 0.0000e+00 - val_loss: -19785.2598 - val_accuracy: 0.0000e+00\n",
      "Epoch 151/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -20357.4395 - accuracy: 0.0000e+00 - val_loss: -19917.1621 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 152/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -20492.7148 - accuracy: 0.0000e+00 - val_loss: -20049.0840 - val_accuracy: 0.0000e+00\n",
      "Epoch 153/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -20627.9824 - accuracy: 0.0000e+00 - val_loss: -20181.0020 - val_accuracy: 0.0000e+00\n",
      "Epoch 154/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -20763.2715 - accuracy: 0.0000e+00 - val_loss: -20312.8516 - val_accuracy: 0.0000e+00\n",
      "Epoch 155/250\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -20898.5371 - accuracy: 0.0000e+00 - val_loss: -20444.8203 - val_accuracy: 0.0000e+00\n",
      "Epoch 156/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -21033.8125 - accuracy: 0.0000e+00 - val_loss: -20576.7227 - val_accuracy: 0.0000e+00\n",
      "Epoch 157/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -21169.0742 - accuracy: 0.0000e+00 - val_loss: -20708.6367 - val_accuracy: 0.0000e+00\n",
      "Epoch 158/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -21304.3828 - accuracy: 0.0000e+00 - val_loss: -20840.5977 - val_accuracy: 0.0000e+00\n",
      "Epoch 159/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -21439.6934 - accuracy: 0.0000e+00 - val_loss: -20972.4883 - val_accuracy: 0.0000e+00\n",
      "Epoch 160/250\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -21574.9629 - accuracy: 0.0000e+00 - val_loss: -21104.4219 - val_accuracy: 0.0000e+00\n",
      "Epoch 161/250\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -21710.2422 - accuracy: 0.0000e+00 - val_loss: -21236.3359 - val_accuracy: 0.0000e+00\n",
      "Epoch 162/250\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -21845.5254 - accuracy: 0.0000e+00 - val_loss: -21368.2402 - val_accuracy: 0.0000e+00\n",
      "Epoch 163/250\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -21980.7949 - accuracy: 0.0000e+00 - val_loss: -21500.1836 - val_accuracy: 0.0000e+00\n",
      "Epoch 164/250\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -22116.1113 - accuracy: 0.0000e+00 - val_loss: -21632.0879 - val_accuracy: 0.0000e+00\n",
      "Epoch 165/250\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -22251.3809 - accuracy: 0.0000e+00 - val_loss: -21764.0391 - val_accuracy: 0.0000e+00\n",
      "Epoch 166/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -22386.6719 - accuracy: 0.0000e+00 - val_loss: -21895.9316 - val_accuracy: 0.0000e+00\n",
      "Epoch 167/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -22521.9336 - accuracy: 0.0000e+00 - val_loss: -22027.8516 - val_accuracy: 0.0000e+00\n",
      "Epoch 168/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -22657.2070 - accuracy: 0.0000e+00 - val_loss: -22159.7305 - val_accuracy: 0.0000e+00\n",
      "Epoch 169/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -22792.5039 - accuracy: 0.0000e+00 - val_loss: -22291.7031 - val_accuracy: 0.0000e+00\n",
      "Epoch 170/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -22927.8164 - accuracy: 0.0000e+00 - val_loss: -22423.6445 - val_accuracy: 0.0000e+00\n",
      "Epoch 171/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -23063.1230 - accuracy: 0.0000e+00 - val_loss: -22555.5723 - val_accuracy: 0.0000e+00\n",
      "Epoch 172/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -23198.3730 - accuracy: 0.0000e+00 - val_loss: -22687.4336 - val_accuracy: 0.0000e+00\n",
      "Epoch 173/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -23333.5820 - accuracy: 0.0000e+00 - val_loss: -22819.2891 - val_accuracy: 0.0000e+00\n",
      "Epoch 174/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -23468.8477 - accuracy: 0.0000e+00 - val_loss: -22951.2363 - val_accuracy: 0.0000e+00\n",
      "Epoch 175/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -23604.1992 - accuracy: 0.0000e+00 - val_loss: -23083.2090 - val_accuracy: 0.0000e+00\n",
      "Epoch 176/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -23739.5195 - accuracy: 0.0000e+00 - val_loss: -23215.1328 - val_accuracy: 0.0000e+00\n",
      "Epoch 177/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -23874.7617 - accuracy: 0.0000e+00 - val_loss: -23347.0039 - val_accuracy: 0.0000e+00\n",
      "Epoch 178/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -24010.0703 - accuracy: 0.0000e+00 - val_loss: -23478.9707 - val_accuracy: 0.0000e+00\n",
      "Epoch 179/250\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -24145.2812 - accuracy: 0.0000e+00 - val_loss: -23610.7617 - val_accuracy: 0.0000e+00\n",
      "Epoch 180/250\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -24280.5430 - accuracy: 0.0000e+00 - val_loss: -23742.7383 - val_accuracy: 0.0000e+00\n",
      "Epoch 181/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -24415.8633 - accuracy: 0.0000e+00 - val_loss: -23874.6895 - val_accuracy: 0.0000e+00\n",
      "Epoch 182/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -24551.1289 - accuracy: 0.0000e+00 - val_loss: -24006.5039 - val_accuracy: 0.0000e+00\n",
      "Epoch 183/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -24686.3848 - accuracy: 0.0000e+00 - val_loss: -24138.4902 - val_accuracy: 0.0000e+00\n",
      "Epoch 184/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -24821.7285 - accuracy: 0.0000e+00 - val_loss: -24270.4395 - val_accuracy: 0.0000e+00\n",
      "Epoch 185/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -24956.9844 - accuracy: 0.0000e+00 - val_loss: -24402.3223 - val_accuracy: 0.0000e+00\n",
      "Epoch 186/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -25092.2344 - accuracy: 0.0000e+00 - val_loss: -24534.2109 - val_accuracy: 0.0000e+00\n",
      "Epoch 187/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -25227.5039 - accuracy: 0.0000e+00 - val_loss: -24666.0723 - val_accuracy: 0.0000e+00\n",
      "Epoch 188/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -25362.7578 - accuracy: 0.0000e+00 - val_loss: -24797.9961 - val_accuracy: 0.0000e+00\n",
      "Epoch 189/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -25498.0020 - accuracy: 0.0000e+00 - val_loss: -24929.8789 - val_accuracy: 0.0000e+00\n",
      "Epoch 190/250\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -25633.3320 - accuracy: 0.0000e+00 - val_loss: -25061.8066 - val_accuracy: 0.0000e+00\n",
      "Epoch 191/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -25768.5996 - accuracy: 0.0000e+00 - val_loss: -25193.7910 - val_accuracy: 0.0000e+00\n",
      "Epoch 192/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -25903.8809 - accuracy: 0.0000e+00 - val_loss: -25325.6504 - val_accuracy: 0.0000e+00\n",
      "Epoch 193/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -26039.1562 - accuracy: 0.0000e+00 - val_loss: -25457.5781 - val_accuracy: 0.0000e+00\n",
      "Epoch 194/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -26174.4023 - accuracy: 0.0000e+00 - val_loss: -25589.4863 - val_accuracy: 0.0000e+00\n",
      "Epoch 195/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -26309.7461 - accuracy: 0.0000e+00 - val_loss: -25721.4316 - val_accuracy: 0.0000e+00\n",
      "Epoch 196/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -26445.0547 - accuracy: 0.0000e+00 - val_loss: -25853.3613 - val_accuracy: 0.0000e+00\n",
      "Epoch 197/250\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -26580.3262 - accuracy: 0.0000e+00 - val_loss: -25985.2617 - val_accuracy: 0.0000e+00\n",
      "Epoch 198/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -26715.5469 - accuracy: 0.0000e+00 - val_loss: -26117.0977 - val_accuracy: 0.0000e+00\n",
      "Epoch 199/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -26850.8262 - accuracy: 0.0000e+00 - val_loss: -26249.0938 - val_accuracy: 0.0000e+00\n",
      "Epoch 200/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -26986.1211 - accuracy: 0.0000e+00 - val_loss: -26381.0059 - val_accuracy: 0.0000e+00\n",
      "Epoch 201/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1008/1008 [==============================] - 2s 2ms/step - loss: -27121.4199 - accuracy: 0.0000e+00 - val_loss: -26512.9180 - val_accuracy: 0.0000e+00\n",
      "Epoch 202/250\n",
      "1008/1008 [==============================] - 3s 2ms/step - loss: -27256.6738 - accuracy: 0.0000e+00 - val_loss: -26644.7793 - val_accuracy: 0.0000e+00\n",
      "Epoch 203/250\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -27391.8926 - accuracy: 0.0000e+00 - val_loss: -26776.6875 - val_accuracy: 0.0000e+00\n",
      "Epoch 204/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -27527.1836 - accuracy: 0.0000e+00 - val_loss: -26908.6289 - val_accuracy: 0.0000e+00\n",
      "Epoch 205/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -27662.4785 - accuracy: 0.0000e+00 - val_loss: -27040.4922 - val_accuracy: 0.0000e+00\n",
      "Epoch 206/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -27797.7676 - accuracy: 0.0000e+00 - val_loss: -27172.4590 - val_accuracy: 0.0000e+00\n",
      "Epoch 207/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -27933.0273 - accuracy: 0.0000e+00 - val_loss: -27304.3496 - val_accuracy: 0.0000e+00\n",
      "Epoch 208/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -28068.3027 - accuracy: 0.0000e+00 - val_loss: -27436.2832 - val_accuracy: 0.0000e+00\n",
      "Epoch 209/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -28203.5977 - accuracy: 0.0000e+00 - val_loss: -27568.2090 - val_accuracy: 0.0000e+00\n",
      "Epoch 210/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -28338.9062 - accuracy: 0.0000e+00 - val_loss: -27700.1387 - val_accuracy: 0.0000e+00\n",
      "Epoch 211/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -28474.1973 - accuracy: 0.0000e+00 - val_loss: -27832.0508 - val_accuracy: 0.0000e+00\n",
      "Epoch 212/250\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -28609.4707 - accuracy: 0.0000e+00 - val_loss: -27963.9805 - val_accuracy: 0.0000e+00\n",
      "Epoch 213/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -28744.7598 - accuracy: 0.0000e+00 - val_loss: -28095.8359 - val_accuracy: 0.0000e+00\n",
      "Epoch 214/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -28879.9961 - accuracy: 0.0000e+00 - val_loss: -28227.7656 - val_accuracy: 0.0000e+00\n",
      "Epoch 215/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -29015.2734 - accuracy: 0.0000e+00 - val_loss: -28359.6719 - val_accuracy: 0.0000e+00\n",
      "Epoch 216/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -29150.5547 - accuracy: 0.0000e+00 - val_loss: -28491.5605 - val_accuracy: 0.0000e+00\n",
      "Epoch 217/250\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -29285.8730 - accuracy: 0.0000e+00 - val_loss: -28623.5098 - val_accuracy: 0.0000e+00\n",
      "Epoch 218/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -29421.1328 - accuracy: 0.0000e+00 - val_loss: -28755.4375 - val_accuracy: 0.0000e+00\n",
      "Epoch 219/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -29556.4043 - accuracy: 0.0000e+00 - val_loss: -28887.3398 - val_accuracy: 0.0000e+00\n",
      "Epoch 220/250\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -29691.6484 - accuracy: 0.0000e+00 - val_loss: -29019.1836 - val_accuracy: 0.0000e+00\n",
      "Epoch 221/250\n",
      "1008/1008 [==============================] - 3s 2ms/step - loss: -29826.8809 - accuracy: 0.0000e+00 - val_loss: -29151.0879 - val_accuracy: 0.0000e+00\n",
      "Epoch 222/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -29962.1719 - accuracy: 0.0000e+00 - val_loss: -29283.0117 - val_accuracy: 0.0000e+00\n",
      "Epoch 223/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -30097.4609 - accuracy: 0.0000e+00 - val_loss: -29414.8926 - val_accuracy: 0.0000e+00\n",
      "Epoch 224/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -30232.7168 - accuracy: 0.0000e+00 - val_loss: -29546.8281 - val_accuracy: 0.0000e+00\n",
      "Epoch 225/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -30367.9961 - accuracy: 0.0000e+00 - val_loss: -29678.7852 - val_accuracy: 0.0000e+00\n",
      "Epoch 226/250\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -30503.2598 - accuracy: 0.0000e+00 - val_loss: -29810.6504 - val_accuracy: 0.0000e+00\n",
      "Epoch 227/250\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -30638.5391 - accuracy: 0.0000e+00 - val_loss: -29942.5859 - val_accuracy: 0.0000e+00\n",
      "Epoch 228/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -30773.8496 - accuracy: 0.0000e+00 - val_loss: -30074.5195 - val_accuracy: 0.0000e+00\n",
      "Epoch 229/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -30909.1484 - accuracy: 0.0000e+00 - val_loss: -30206.4297 - val_accuracy: 0.0000e+00\n",
      "Epoch 230/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -31044.4297 - accuracy: 0.0000e+00 - val_loss: -30338.3438 - val_accuracy: 0.0000e+00\n",
      "Epoch 231/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -31179.6875 - accuracy: 0.0000e+00 - val_loss: -30470.2422 - val_accuracy: 0.0000e+00\n",
      "Epoch 232/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -31314.9336 - accuracy: 0.0000e+00 - val_loss: -30602.1387 - val_accuracy: 0.0000e+00\n",
      "Epoch 233/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -31450.2480 - accuracy: 0.0000e+00 - val_loss: -30734.0586 - val_accuracy: 0.0000e+00\n",
      "Epoch 234/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -31585.5117 - accuracy: 0.0000e+00 - val_loss: -30866.0020 - val_accuracy: 0.0000e+00\n",
      "Epoch 235/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -31720.7812 - accuracy: 0.0000e+00 - val_loss: -30997.8574 - val_accuracy: 0.0000e+00\n",
      "Epoch 236/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -31856.0566 - accuracy: 0.0000e+00 - val_loss: -31129.8008 - val_accuracy: 0.0000e+00\n",
      "Epoch 237/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -31991.3496 - accuracy: 0.0000e+00 - val_loss: -31261.7109 - val_accuracy: 0.0000e+00\n",
      "Epoch 238/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -32126.6465 - accuracy: 0.0000e+00 - val_loss: -31393.6895 - val_accuracy: 0.0000e+00\n",
      "Epoch 239/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -32261.9551 - accuracy: 0.0000e+00 - val_loss: -31525.5996 - val_accuracy: 0.0000e+00\n",
      "Epoch 240/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -32397.2773 - accuracy: 0.0000e+00 - val_loss: -31657.5918 - val_accuracy: 0.0000e+00\n",
      "Epoch 241/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -32532.5645 - accuracy: 0.0000e+00 - val_loss: -31789.4785 - val_accuracy: 0.0000e+00\n",
      "Epoch 242/250\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -32667.8340 - accuracy: 0.0000e+00 - val_loss: -31921.4219 - val_accuracy: 0.0000e+00\n",
      "Epoch 243/250\n",
      "1008/1008 [==============================] - 5s 5ms/step - loss: -32803.1094 - accuracy: 0.0000e+00 - val_loss: -32053.3281 - val_accuracy: 0.0000e+00\n",
      "Epoch 244/250\n",
      "1008/1008 [==============================] - 5s 5ms/step - loss: -32938.4492 - accuracy: 0.0000e+00 - val_loss: -32185.2266 - val_accuracy: 0.0000e+00\n",
      "Epoch 245/250\n",
      "1008/1008 [==============================] - 5s 5ms/step - loss: -33073.6875 - accuracy: 0.0000e+00 - val_loss: -32317.1270 - val_accuracy: 0.0000e+00\n",
      "Epoch 246/250\n",
      "1008/1008 [==============================] - 5s 5ms/step - loss: -33208.9492 - accuracy: 0.0000e+00 - val_loss: -32449.0059 - val_accuracy: 0.0000e+00\n",
      "Epoch 247/250\n",
      "1008/1008 [==============================] - 5s 5ms/step - loss: -33344.1602 - accuracy: 0.0000e+00 - val_loss: -32580.8945 - val_accuracy: 0.0000e+00\n",
      "Epoch 248/250\n",
      "1008/1008 [==============================] - 5s 5ms/step - loss: -33479.4570 - accuracy: 0.0000e+00 - val_loss: -32712.8848 - val_accuracy: 0.0000e+00\n",
      "Epoch 249/250\n",
      "1008/1008 [==============================] - 5s 5ms/step - loss: -33614.7344 - accuracy: 0.0000e+00 - val_loss: -32844.7422 - val_accuracy: 0.0000e+00\n",
      "Epoch 250/250\n",
      "1008/1008 [==============================] - 5s 5ms/step - loss: -33750.0625 - accuracy: 0.0000e+00 - val_loss: -32976.6914 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "history=model.fit(X_org, Y_org, validation_split=0.33, epochs=250, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "05f3a581",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-28T13:04:11.621937Z",
     "start_time": "2022-06-28T13:04:11.030642Z"
    }
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'sequential_6/dense_18/Relu' defined at (most recent call last):\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 457, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 446, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 353, in dispatch_shell\n      await result\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 648, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2901, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2947, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3172, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3364, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3444, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\DELL\\AppData\\Local\\Temp/ipykernel_240/2347671958.py\", line 2, in <module>\n      scores = model.evaluate(X_amb, Y2_amb)\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1756, in evaluate\n      tmp_logs = self.test_function(iterator)\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1557, in test_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1546, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1535, in run_step\n      outputs = model.test_step(data)\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1499, in test_step\n      y_pred = self(x, training=False)\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\keras\\engine\\sequential.py\", line 374, in call\n      return super(Sequential, self).call(inputs, training=training, mask=mask)\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 458, in call\n      return self._run_internal_graph(\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 596, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\keras\\layers\\core\\dense.py\", line 235, in call\n      outputs = self.activation(outputs)\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\keras\\activations.py\", line 311, in relu\n      return backend.relu(x, alpha=alpha, max_value=max_value, threshold=threshold)\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\keras\\backend.py\", line 4992, in relu\n      x = tf.nn.relu(x)\nNode: 'sequential_6/dense_18/Relu'\nMatrix size-incompatible: In[0]: [32,4], In[1]: [3,12]\n\t [[{{node sequential_6/dense_18/Relu}}]] [Op:__inference_test_function_4485949]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_240/2347671958.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# evaluate the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_amb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY2_amb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s: %.2f%%\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'sequential_6/dense_18/Relu' defined at (most recent call last):\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 457, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 446, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 353, in dispatch_shell\n      await result\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 648, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2901, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2947, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3172, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3364, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3444, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\DELL\\AppData\\Local\\Temp/ipykernel_240/2347671958.py\", line 2, in <module>\n      scores = model.evaluate(X_amb, Y2_amb)\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1756, in evaluate\n      tmp_logs = self.test_function(iterator)\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1557, in test_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1546, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1535, in run_step\n      outputs = model.test_step(data)\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1499, in test_step\n      y_pred = self(x, training=False)\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\keras\\engine\\sequential.py\", line 374, in call\n      return super(Sequential, self).call(inputs, training=training, mask=mask)\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 458, in call\n      return self._run_internal_graph(\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 596, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\keras\\layers\\core\\dense.py\", line 235, in call\n      outputs = self.activation(outputs)\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\keras\\activations.py\", line 311, in relu\n      return backend.relu(x, alpha=alpha, max_value=max_value, threshold=threshold)\n    File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\keras\\backend.py\", line 4992, in relu\n      x = tf.nn.relu(x)\nNode: 'sequential_6/dense_18/Relu'\nMatrix size-incompatible: In[0]: [32,4], In[1]: [3,12]\n\t [[{{node sequential_6/dense_18/Relu}}]] [Op:__inference_test_function_4485949]"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(X_amb, Y2_amb)\n",
    "print(scores)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aee3c5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
